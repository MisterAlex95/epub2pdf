"""
Module de traitement d'images pour la conversion PDF - Version optimis√©e
"""

import os
import time
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from .base_converter import BaseConverter


class ImageProcessor(BaseConverter):
    """Processeur d'images optimis√© pour la conversion PDF"""
    
    def __init__(self, max_workers: int = 5, logger=None):
        super().__init__(max_workers, logger)
        # Initialiser le PDFMerger
        from .pdf_merger import PDFMerger
        self.pdf_merger = PDFMerger(max_workers, logger)
        
        # Optimisations de performance
        self._image_cache = {}  # Cache pour les images fr√©quemment utilis√©es
        self._max_cache_size = 50  # Taille maximale du cache
        
    def convert_images_to_pdf(self, image_paths: List[str], output_path: str, options: Dict) -> bool:
        """Convertit les images en PDF avec parall√©lisme optimis√© et ordre personnalisable"""
        try:
            start_time = time.time()
            
            # D√©dupliquer les chemins d'images
            unique_paths = list(set(image_paths))
            if len(unique_paths) != len(image_paths):
                self.logger.warning(f"‚ö†Ô∏è {len(image_paths) - len(unique_paths)} images dupliqu√©es supprim√©es")
                image_paths = unique_paths
            
            # Trier les images une fois de plus pour garantir l'ordre
            self.logger.info(f"üîÑ Tri final de {len(image_paths)} images...")
            image_paths.sort(key=lambda x: self._natural_sort_key(x))
            
            # Appliquer l'ordre de fusion selon les options
            merge_order = options.get('merge_order', 'Naturel')
            if merge_order == "Alphab√©tique":
                image_paths.sort(key=lambda x: Path(x).name.lower())
                self.logger.info("üìù Tri alphab√©tique appliqu√©")
            elif merge_order == "Invers√©":
                image_paths.reverse()
                self.logger.info("üîÑ Ordre invers√© appliqu√©")
            elif merge_order == "Personnalis√©":
                # Pour l'instant, garder l'ordre naturel
                # TODO: Impl√©menter l'ordre personnalis√© avec interface
                self.logger.info("‚öôÔ∏è Ordre personnalis√© (utilise l'ordre naturel)")
            
            # Diviser les images en groupes optimis√©s
            group_size = self._calculate_optimal_group_size(len(image_paths), options)
            groups = [image_paths[i:i + group_size] for i in range(0, len(image_paths), group_size)]
            
            self.logger.info(f"üì¶ Division en {len(groups)} groupes de {group_size} images max")
            
            # Conversion parall√®le optimis√©e avec ThreadPoolExecutor
            temp_pdfs = self._convert_groups_parallel(groups, options)
            
            if not temp_pdfs:
                self.logger.error("‚ùå Aucun PDF temporaire cr√©√©")
                return False
            
            # Trier les PDFs par num√©ro de groupe pour maintenir l'ordre
            temp_pdfs.sort(key=lambda x: x[0])
            sorted_pdfs = [pdf for _, pdf in temp_pdfs]
            
            # D√©dupliquer les PDFs avant fusion
            unique_pdfs = list(set(sorted_pdfs))
            if len(unique_pdfs) != len(sorted_pdfs):
                self.logger.warning(f"‚ö†Ô∏è {len(sorted_pdfs) - len(unique_pdfs)} PDFs dupliqu√©s supprim√©s avant fusion")
            
            # Fusionner les PDFs temporaires
            if unique_pdfs:
                self.logger.info(f"üîÑ Fusion de {len(unique_pdfs)} PDFs...")
                success = self.pdf_merger.merge_pdfs(unique_pdfs, output_path)
                
                if success:
                    elapsed_time = time.time() - start_time
                    self.logger.info(f"‚úÖ Conversion termin√©e en {elapsed_time:.2f}s")
                    
                    # Nettoyer le cache
                    self._clear_cache()
                    
                return success
            else:
                self.logger.error("‚ùå Aucun PDF temporaire cr√©√©")
                return False
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur conversion parall√®le: {e}")
            return False
    
    def _convert_groups_parallel(self, groups: List[List[str]], options: Dict) -> List[Tuple[int, str]]:
        """Convertit les groupes en parall√®le avec ThreadPoolExecutor"""
        temp_pdfs = []
        successful_groups = 0
        min_success_rate = max(1, len(groups) // 3)  # Au moins 33% des groupes
        
        # Utiliser ThreadPoolExecutor pour le parall√©lisme
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Soumettre toutes les t√¢ches
            future_to_group = {
                executor.submit(self._convert_group_to_pdf, group, i, options): i 
                for i, group in enumerate(groups)
            }
            
            # Traiter les r√©sultats au fur et √† mesure
            for future in as_completed(future_to_group):
                group_num = future_to_group[future]
                try:
                    temp_pdf = future.result()
                    if temp_pdf:
                        temp_pdfs.append((group_num, temp_pdf))
                        successful_groups += 1
                        self.logger.info(f"‚úÖ Groupe {group_num + 1}/{len(groups)} termin√©")
                    else:
                        self.logger.warning(f"‚ö†Ô∏è Groupe {group_num + 1}/{len(groups)} √©chou√©")
                except Exception as e:
                    self.logger.error(f"‚ùå Erreur groupe {group_num + 1}: {e}")
        
        # V√©rifier le taux de succ√®s
        success_rate = successful_groups / len(groups) * 100
        self.logger.info(f"üìä Taux de succ√®s: {success_rate:.1f}% ({successful_groups}/{len(groups)} groupes)")
        
        if successful_groups < min_success_rate:
            self.logger.error(f"‚ùå Taux de succ√®s trop faible: {success_rate:.1f}% < 33.3%")
            return []
        
        return temp_pdfs
    
    def _calculate_optimal_group_size(self, total_images: int, options: Dict) -> int:
        """Calcule la taille optimale des groupes avec heuristiques avanc√©es"""
        veryfast = options.get('veryfast_mode', False)
        fast = options.get('fast_mode', False)
        
        # Taille de base selon le mode
        if veryfast:
            base_size = 60  # Plus grand pour plus de vitesse
        elif fast:
            base_size = 40
        else:
            base_size = 25
        
        # Ajuster selon le nombre de workers et la m√©moire disponible
        if self.max_workers > 6:
            group_size = base_size // 2
        elif self.max_workers < 3:
            group_size = base_size * 1.5
        else:
            group_size = base_size
        
        # Ajuster selon le nombre total d'images
        if total_images > 1000:
            group_size = min(group_size, 30)  # Limiter pour √©viter la surcharge m√©moire
        elif total_images < 100:
            group_size = max(group_size, 15)  # Groupe minimum pour l'efficacit√©
        
        # Taille minimale et maximale
        return max(10, min(group_size, total_images // max(1, self.max_workers)))
    
    def _convert_group_to_pdf(self, image_paths: List[str], group_num: int, options: Dict) -> Optional[str]:
        """Convertit un groupe d'images en PDF temporaire avec optimisations"""
        try:
            if not image_paths:
                self.logger.warning(f"‚ö†Ô∏è Groupe {group_num}: Aucune image fournie")
                return None
            
            # V√©rifier que les images existent et sont valides
            valid_images = self._validate_images(image_paths, group_num)
            if not valid_images:
                return None
            
            # Cr√©er le PDF temporaire avec chemin relatif
            temp_pdf = str(self.temp_dir / f"group_{group_num}.pdf")
            self.logger.debug(f"üìÑ Cr√©ation PDF temporaire: {temp_pdf}")
            
            # Utiliser Pillow avec optimisations
            try:
                self.logger.debug(f"üîÑ Chargement de {len(valid_images)} images valides")
                images = self._load_images_optimized(valid_images, options)
                
                if not images:
                    self.logger.warning(f"‚ö†Ô∏è Groupe {group_num}: Aucune image charg√©e")
                    return None
                
                # Sauvegarder en PDF de mani√®re optimis√©e
                success = self._save_pdf_optimized(images, temp_pdf, group_num)
                
                # Forcer la fermeture des images pour lib√©rer la m√©moire
                for img in images:
                    img.close()
                
                return temp_pdf if success else None
                        
            except Exception as e:
                self.logger.error(f"‚ùå Erreur conversion groupe {group_num}: {e}")
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur g√©n√©rale groupe {group_num}: {e}")
            return None
    
    def _validate_images(self, image_paths: List[str], group_num: int) -> List[str]:
        """Valide les images et retourne les chemins valides"""
        valid_images = []
        for img_path in image_paths:
            if os.path.exists(img_path) and os.path.getsize(img_path) > 0:
                valid_images.append(img_path)
            else:
                self.logger.warning(f"‚ö†Ô∏è Fichier inexistant ou vide: {img_path}")
        
        if not valid_images:
            self.logger.warning(f"‚ö†Ô∏è Groupe {group_num}: Aucune image valide")
        
        return valid_images
    
    def _load_images_optimized(self, image_paths: List[str], options: Dict) -> List:
        """Charge les images avec optimisations de m√©moire et cache"""
        images = []
        
        for i, img_path in enumerate(image_paths):
            try:
                # V√©rifier le cache d'abord
                if img_path in self._image_cache:
                    self.logger.debug(f"üì∑ Cache hit: {Path(img_path).name}")
                    cached_img = self._image_cache[img_path].copy()
                    images.append(cached_img)
                    continue
                
                self.logger.debug(f"üì∑ Chargement image {i+1}/{len(image_paths)}: {Path(img_path).name}")
                
                with self._open_image(img_path) as img:
                    # Appliquer les options
                    img = self._apply_image_options(img, options)
                    
                    # Copie pour √©viter les probl√®mes
                    img_copy = img.copy()
                    images.append(img_copy)
                    
                    # Mettre en cache si possible
                    self._add_to_cache(img_path, img_copy)
                    
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erreur ouverture {img_path}: {e}")
                continue
        
        return images
    
    def _save_pdf_optimized(self, images: List, temp_pdf: str, group_num: int) -> bool:
        """Sauvegarde optimis√©e en PDF"""
        try:
            self.logger.debug(f"üîÑ Sauvegarde PDF groupe {group_num}: {len(images)} images")
            
            # M√©thode optimis√©e selon le nombre d'images
            if len(images) == 1:
                # Un seul PDF
                self.logger.debug(f"üìÑ Sauvegarde PDF unique: {temp_pdf}")
                images[0].save(temp_pdf, 'PDF', resolution=100.0, optimize=True)
            else:
                # Plusieurs images - m√©thode s√©quentielle optimis√©e
                first_image = images[0]
                other_images = images[1:]
                
                self.logger.debug(f"üìÑ Sauvegarde PDF multiple: {temp_pdf} ({len(other_images)} images suppl√©mentaires)")
                
                # Cr√©er le PDF avec la premi√®re image et optimisations
                first_image.save(temp_pdf, 'PDF', resolution=100.0, save_all=True, 
                             append_images=other_images, optimize=True)
            
            # Attendre un peu pour s'assurer que le fichier est bien √©crit
            time.sleep(0.1)  # R√©duit pour plus de performance
            
            # V√©rification rapide du PDF
            return self._verify_pdf_file(temp_pdf, group_num, len(images))
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur sauvegarde PDF groupe {group_num}: {e}")
            return False
    
    def _verify_pdf_file(self, temp_pdf: str, group_num: int, num_images: int) -> bool:
        """V√©rification rapide et optimis√©e du fichier PDF"""
        if not os.path.exists(temp_pdf):
            self.logger.warning(f"‚ö†Ô∏è Groupe {group_num}: PDF non cr√©√©: {temp_pdf}")
            return False
        
        file_size = os.path.getsize(temp_pdf)
        self.logger.debug(f"üìè Taille du PDF cr√©√©: {file_size} bytes")
        
        if file_size < 1000:  # Au moins 1KB
            self.logger.warning(f"‚ö†Ô∏è Groupe {group_num}: PDF trop petit ({file_size} bytes)")
            return False
        
        # V√©rification rapide du header PDF
        try:
            with open(temp_pdf, 'rb') as f:
                header = f.read(4)
                if header != b'%PDF':
                    self.logger.warning(f"‚ö†Ô∏è Groupe {group_num}: PDF invalide (header incorrect: {header})")
                    return False
                
                # V√©rification rapide de la fin
                f.seek(-50, 2)  # Aller √† 50 bytes de la fin
                end_content = f.read()
                if b'%%EOF' not in end_content:
                    self.logger.warning(f"‚ö†Ô∏è Groupe {group_num}: PDF incomplet (pas de %%EOF)")
                    return False
                
                self.logger.debug(f"‚úÖ Groupe {group_num}: PDF valide cr√©√© ({num_images} images, {file_size} bytes)")
                return True
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Groupe {group_num}: Erreur v√©rification PDF: {e}")
            return False
    
    def _add_to_cache(self, img_path: str, img):
        """Ajoute une image au cache avec gestion de la taille"""
        if len(self._image_cache) >= self._max_cache_size:
            # Supprimer l'√©l√©ment le plus ancien
            oldest_key = next(iter(self._image_cache))
            del self._image_cache[oldest_key]
        
        self._image_cache[img_path] = img
    
    def _clear_cache(self):
        """Nettoie le cache d'images"""
        self._image_cache.clear()
    
    def _open_image(self, img_path: str):
        """Ouvre une image avec Pillow"""
        from PIL import Image
        return Image.open(img_path)
    
    def _apply_image_options(self, img, options: Dict):
        """Applique les options de traitement √† une image avec optimisations"""
        # Convertir en RGB si n√©cessaire
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # Appliquer les options
        if options.get('grayscale', False):
            img = img.convert('L').convert('RGB')
        
        resize = options.get('resize')
        if resize:
            img = self._resize_image(img, resize)
        
        return img
    
    def _resize_image(self, img, resize: str):
        """Redimensionne une image selon les param√®tres avec optimisations"""
        try:
            from PIL import Image
            
            # D√©finir les tailles cibles optimis√©es
            target_sizes = {
                "A4": (595, 842),      # A4: 210x297mm √† 72dpi
                "Letter": (612, 792),   # Letter: 8.5x11" √† 72dpi
                "A3": (842, 1191),     # A3: 297x420mm √† 72dpi
                "A5": (420, 595),      # A5: 148x210mm √† 72dpi
                "HD": (1280, 720),     # HD standard
                "FHD": (1920, 1080),   # Full HD
            }
            
            target_size = target_sizes.get(resize)
            if not target_size:
                return img
            
            # Redimensionner en conservant les proportions avec LANCZOS (meilleure qualit√©)
            img.thumbnail(target_size, Image.Resampling.LANCZOS)
            return img
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Erreur redimensionnement: {e}")
            return img
